{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "191216TF_IPIP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhuang12/Tensorflow-for-personality-items-classification/blob/master/191216TF_IPIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52bYMFnQprcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS NOTEBOOK WAS CREATED TO USE TF NLP FOR IPIP ITEMS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkBl41YZNuzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HmQPn2QLInf",
        "colab_type": "code",
        "outputId": "a3297fd3-a769-42d5-89df-f71e888f07ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Di92YMtLRR-",
        "colab_type": "code",
        "outputId": "9db883ed-fc5a-4562-de0e-38403d46d759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (42.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVnl38Ttp19e",
        "colab_type": "text"
      },
      "source": [
        "DATA LOADING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WLvGKL-p1Qx",
        "colab_type": "code",
        "outputId": "46927de9-55a0-439e-ae2b-915b3f0b6fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWPpXW6IMU24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dpath = os.path.join(r\"C:/Users/amead/Google Drive/active/machine learning/big5/big_five_items.csv\")\n",
        "dpath = os.path.join(\"/content/drive/My Drive/big_five_items.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XVQVhbQMw-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(dpath,low_memory = False, sep = \"\\t\", lineterminator = '\\n', encoding = 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTEs9VUUO6RB",
        "colab_type": "text"
      },
      "source": [
        "DATA PROCESSING\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82XZ2o3yO_ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stem as one string\n",
        "sentences = pd.Series(data['Stem'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3g2CgyHRu4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scale as categorical data\n",
        "data['labels'] = data['Scale'].astype('category').cat.codes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJJoFen1Uj03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.array(pd.Series(data['labels']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp0mlKadp8x8",
        "colab_type": "text"
      },
      "source": [
        "DATA CLEANING (STEMMING)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjR16yfrWvZ5",
        "colab_type": "text"
      },
      "source": [
        "TOKENIZATION AND PADDING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RahwW-DvWucE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# tokenizer = Tokenizer(oov_token = \"<OOV>\", num_words = 10000)\n",
        "# tokenizer.fit_on_texts(sentences)\n",
        "# word_index = tokenizer.word_index\n",
        "# print(word_index)\n",
        "\n",
        "# sequences = tokenizer.texts_to_sequences(sentences)\n",
        "# padded = pad_sequences(sequences, padding = 'pre')\n",
        "# print(padded[0])\n",
        "# print(padded.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzQw4-FfqDGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split training and validation sample\n",
        "#training_data, training_labels = np.asarray(padded[ :524]), labels[ :524]\n",
        "#test_data, test_labels = np.asarray(padded[525: ]), labels[525: ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPRZsKqNqAzI",
        "colab_type": "text"
      },
      "source": [
        "TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djKwOT6_mPVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "random.seed(700)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjsXQIDLp3WR",
        "colab": {}
      },
      "source": [
        "#stratified random sampling training and validation sample by dimensions\n",
        "\n",
        "training_data = []\n",
        "training_labels = []\n",
        "validation_data = []\n",
        "validation_labels = []\n",
        "\n",
        "for s in range(5):\n",
        "  training_set = data.loc[data['labels'] == s, 'Stem'].sample(frac = 0.7, replace = False, random_state = 1)\n",
        "  training_l = np.array([s]*len(training_set))\n",
        "\n",
        "  validation_set = data.loc[(~data['Stem'].isin(training_set)) & (data['labels'] == s), 'Stem']\n",
        "  validation_l = np.array([s]*len(validation_set))\n",
        "\n",
        "  training_data.extend(training_set)\n",
        "  training_labels.extend(training_l)\n",
        "\n",
        "  validation_data.extend(validation_set)\n",
        "  validation_labels.extend(validation_l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySUmrKW22KE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LENGTH = 10000\n",
        "\n",
        "def sequence_vectorization (train_texts, val_texts): \n",
        "  \"\"\"Vectorizes texts as sequence vectors.\n",
        "\n",
        "    1 text = 1 sequence vector with fixed length.\n",
        "\n",
        "    # Arguments\n",
        "        train_texts: list, training text strings.\n",
        "        val_texts: list, validation text strings.\n",
        "\n",
        "    # Returns\n",
        "        x_train, x_val, word_index: vectorized training and validation\n",
        "            texts and word index dictionary.\n",
        "  \"\"\"\n",
        "  tokenizer = Tokenizer(oov_token = \"<OOV>\", num_words = MAX_LENGTH)\n",
        "  # Create vocabulary with training texts.\n",
        "  tokenizer.fit_on_texts(train_texts)\n",
        "  x_train = tokenizer.texts_to_sequences(train_texts)\n",
        "  x_val = tokenizer.texts_to_sequences(val_texts)\n",
        "  \n",
        "  # Get max sequence length.\n",
        "  max_length = len(max(x_train, key=len))\n",
        "  \n",
        "  if max_length > MAX_LENGTH:\n",
        "    max_length = MAX_LENGTH\n",
        " \n",
        "# Fix sequence length to max value. Sequences shorter than the length are\n",
        "# padded in the beginning and sequences longer are truncated\n",
        "# at the beginning.\n",
        "  x_train = np.asarray(pad_sequences(x_train, maxlen=max_length))\n",
        "  x_val = np.asarray(pad_sequences(x_val, maxlen=max_length))\n",
        "\n",
        "  return x_train, x_val, tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUCHHm7xj2p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_vec, val_vec, word_index = sequence_vectorization(training_data, validation_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r106kAqj6Roh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_labels = np.array(training_labels)\n",
        "validation_labels = np.array(validation_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1KVlwVE1qzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#summary of tokenization - validation data\n",
        "# print(tokenizer.word_counts)\n",
        "# print(tokenizer.document_count)\n",
        "# print(tokenizer.word_index)\n",
        "# print(tokenizer.word_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC-s3jc7qH8Q",
        "colab_type": "text"
      },
      "source": [
        "MODEL BUILING - MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pPj0LZjZkXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ACCURACY_STOP = 0.95\n",
        "\n",
        "class myCallbacks(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if (logs.get('accuracy')> ACCURACY_STOP):\n",
        "      self.model.stop_training = True\n",
        "      print(\"\\nReach accuracy of 95% and stop training!\")\n",
        "\n",
        "callbacks = myCallbacks()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGnjMaSYn1V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_directory = '/content/drive/My Drive/NLP_tensorflow/sequentia_model.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_directory,\n",
        "                             monitor = \"val_accuracy\", \n",
        "                             save_best_only = True, \n",
        "                             mode = 'max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-x9yGNwAUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_last_layer_units_and_activation(num_classes):\n",
        "    \"\"\"Gets the # units and activation function for the last network layer.\n",
        "\n",
        "    # Arguments\n",
        "        num_classes: int, number of classes.\n",
        "\n",
        "    # Returns\n",
        "        units, activation values.\n",
        "    \"\"\"\n",
        "    if num_classes == 2:\n",
        "        activation = 'sigmoid'\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = 'softmax'\n",
        "        units = num_classes\n",
        "    return units, activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y_7yzwQHI_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4IqBtVJAkOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_model(layers, units, dropout_rate, num_classes):\n",
        "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        An MLP model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "    #model.add(Dropout(rate = dropout_rate)\n",
        "    \n",
        "    for i in range(layers-1):\n",
        "      model.add(Dense(units = units, activation='sigmoid'))\n",
        "      #model.add(Dropout(rate = dropout_rate))\n",
        "\n",
        "    model.add(Dense(units=op_units, activation=op_activation))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB96fiqIl4h0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = 4\n",
        "units = 12\n",
        "dropout_rate = 0.1\n",
        "#input_shape = 1\n",
        "num_classes = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCtGDpPIA0ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_model = mlp_model(layers, units, dropout_rate, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWW8utx3HOs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer = 'adam', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tTcnJsKHker",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02d759c7-d089-483e-9113-a9fbf13d2b46"
      },
      "source": [
        "NUM_EPOCHS = 50\n",
        "history = mlp_model.fit(train_vec, training_labels,\n",
        "                    validation_data = (val_vec, validation_labels),\n",
        "                    epochs = NUM_EPOCHS, \n",
        "                    callbacks = [checkpoint, callbacks])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/50\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 1.6319 - accuracy: 0.1983 - val_loss: 1.6166 - val_accuracy: 0.2022\n",
            "Epoch 2/50\n",
            "459/459 [==============================] - 0s 102us/sample - loss: 1.6192 - accuracy: 0.1983 - val_loss: 1.6105 - val_accuracy: 0.2022\n",
            "Epoch 3/50\n",
            "459/459 [==============================] - 0s 94us/sample - loss: 1.6120 - accuracy: 0.1983 - val_loss: 1.6084 - val_accuracy: 0.2077\n",
            "Epoch 4/50\n",
            "459/459 [==============================] - 0s 106us/sample - loss: 1.6088 - accuracy: 0.1961 - val_loss: 1.6077 - val_accuracy: 0.2459\n",
            "Epoch 5/50\n",
            "459/459 [==============================] - 0s 103us/sample - loss: 1.6074 - accuracy: 0.2048 - val_loss: 1.6081 - val_accuracy: 0.1749\n",
            "Epoch 6/50\n",
            "459/459 [==============================] - 0s 111us/sample - loss: 1.6070 - accuracy: 0.2266 - val_loss: 1.6083 - val_accuracy: 0.2186\n",
            "Epoch 7/50\n",
            "459/459 [==============================] - 0s 106us/sample - loss: 1.6070 - accuracy: 0.2266 - val_loss: 1.6087 - val_accuracy: 0.2295\n",
            "Epoch 8/50\n",
            "459/459 [==============================] - 0s 98us/sample - loss: 1.6059 - accuracy: 0.2070 - val_loss: 1.6085 - val_accuracy: 0.1585\n",
            "Epoch 9/50\n",
            "459/459 [==============================] - 0s 122us/sample - loss: 1.6059 - accuracy: 0.2331 - val_loss: 1.6087 - val_accuracy: 0.1858\n",
            "Epoch 10/50\n",
            "459/459 [==============================] - 0s 104us/sample - loss: 1.6054 - accuracy: 0.2200 - val_loss: 1.6084 - val_accuracy: 0.1694\n",
            "Epoch 11/50\n",
            "459/459 [==============================] - 0s 108us/sample - loss: 1.6051 - accuracy: 0.2309 - val_loss: 1.6088 - val_accuracy: 0.1913\n",
            "Epoch 12/50\n",
            "459/459 [==============================] - 0s 101us/sample - loss: 1.6049 - accuracy: 0.2135 - val_loss: 1.6087 - val_accuracy: 0.2131\n",
            "Epoch 13/50\n",
            "459/459 [==============================] - 0s 105us/sample - loss: 1.6045 - accuracy: 0.2200 - val_loss: 1.6084 - val_accuracy: 0.2186\n",
            "Epoch 14/50\n",
            "459/459 [==============================] - 0s 105us/sample - loss: 1.6053 - accuracy: 0.2244 - val_loss: 1.6080 - val_accuracy: 0.1749\n",
            "Epoch 15/50\n",
            "459/459 [==============================] - 0s 115us/sample - loss: 1.6051 - accuracy: 0.2244 - val_loss: 1.6088 - val_accuracy: 0.1803\n",
            "Epoch 16/50\n",
            "459/459 [==============================] - 0s 100us/sample - loss: 1.6047 - accuracy: 0.2157 - val_loss: 1.6090 - val_accuracy: 0.2022\n",
            "Epoch 17/50\n",
            "459/459 [==============================] - 0s 103us/sample - loss: 1.6045 - accuracy: 0.2266 - val_loss: 1.6089 - val_accuracy: 0.2240\n",
            "Epoch 18/50\n",
            "459/459 [==============================] - 0s 121us/sample - loss: 1.6036 - accuracy: 0.2309 - val_loss: 1.6087 - val_accuracy: 0.2131\n",
            "Epoch 19/50\n",
            "459/459 [==============================] - 0s 111us/sample - loss: 1.6028 - accuracy: 0.2288 - val_loss: 1.6088 - val_accuracy: 0.2459\n",
            "Epoch 20/50\n",
            "459/459 [==============================] - 0s 96us/sample - loss: 1.6030 - accuracy: 0.2222 - val_loss: 1.6090 - val_accuracy: 0.2404\n",
            "Epoch 21/50\n",
            "459/459 [==============================] - 0s 98us/sample - loss: 1.6026 - accuracy: 0.2353 - val_loss: 1.6089 - val_accuracy: 0.2131\n",
            "Epoch 22/50\n",
            "459/459 [==============================] - 0s 100us/sample - loss: 1.6021 - accuracy: 0.2571 - val_loss: 1.6088 - val_accuracy: 0.2295\n",
            "Epoch 23/50\n",
            "459/459 [==============================] - 0s 104us/sample - loss: 1.6022 - accuracy: 0.2418 - val_loss: 1.6089 - val_accuracy: 0.1967\n",
            "Epoch 24/50\n",
            "459/459 [==============================] - 0s 97us/sample - loss: 1.6017 - accuracy: 0.2397 - val_loss: 1.6089 - val_accuracy: 0.2295\n",
            "Epoch 25/50\n",
            "459/459 [==============================] - 0s 93us/sample - loss: 1.6017 - accuracy: 0.2527 - val_loss: 1.6087 - val_accuracy: 0.2240\n",
            "Epoch 26/50\n",
            "459/459 [==============================] - 0s 105us/sample - loss: 1.6016 - accuracy: 0.2549 - val_loss: 1.6083 - val_accuracy: 0.2295\n",
            "Epoch 27/50\n",
            "459/459 [==============================] - 0s 150us/sample - loss: 1.6008 - accuracy: 0.2636 - val_loss: 1.6085 - val_accuracy: 0.2350\n",
            "Epoch 28/50\n",
            "459/459 [==============================] - 0s 106us/sample - loss: 1.6008 - accuracy: 0.2549 - val_loss: 1.6088 - val_accuracy: 0.2186\n",
            "Epoch 29/50\n",
            "459/459 [==============================] - 0s 111us/sample - loss: 1.6001 - accuracy: 0.2658 - val_loss: 1.6084 - val_accuracy: 0.2350\n",
            "Epoch 30/50\n",
            "459/459 [==============================] - 0s 103us/sample - loss: 1.6002 - accuracy: 0.2375 - val_loss: 1.6086 - val_accuracy: 0.2240\n",
            "Epoch 31/50\n",
            "459/459 [==============================] - 0s 96us/sample - loss: 1.6000 - accuracy: 0.2375 - val_loss: 1.6076 - val_accuracy: 0.2186\n",
            "Epoch 32/50\n",
            "459/459 [==============================] - 0s 105us/sample - loss: 1.5988 - accuracy: 0.2397 - val_loss: 1.6084 - val_accuracy: 0.2240\n",
            "Epoch 33/50\n",
            "459/459 [==============================] - 0s 105us/sample - loss: 1.5987 - accuracy: 0.2614 - val_loss: 1.6089 - val_accuracy: 0.2404\n",
            "Epoch 34/50\n",
            "459/459 [==============================] - 0s 109us/sample - loss: 1.5981 - accuracy: 0.2593 - val_loss: 1.6086 - val_accuracy: 0.2295\n",
            "Epoch 35/50\n",
            "459/459 [==============================] - 0s 109us/sample - loss: 1.5978 - accuracy: 0.2571 - val_loss: 1.6087 - val_accuracy: 0.2186\n",
            "Epoch 36/50\n",
            "459/459 [==============================] - 0s 111us/sample - loss: 1.5978 - accuracy: 0.2593 - val_loss: 1.6083 - val_accuracy: 0.2295\n",
            "Epoch 37/50\n",
            "459/459 [==============================] - 0s 106us/sample - loss: 1.5965 - accuracy: 0.2614 - val_loss: 1.6081 - val_accuracy: 0.2459\n",
            "Epoch 38/50\n",
            "459/459 [==============================] - 0s 111us/sample - loss: 1.5971 - accuracy: 0.2745 - val_loss: 1.6086 - val_accuracy: 0.2240\n",
            "Epoch 39/50\n",
            "459/459 [==============================] - 0s 98us/sample - loss: 1.5967 - accuracy: 0.2593 - val_loss: 1.6091 - val_accuracy: 0.2077\n",
            "Epoch 40/50\n",
            "459/459 [==============================] - 0s 110us/sample - loss: 1.5958 - accuracy: 0.2810 - val_loss: 1.6083 - val_accuracy: 0.2295\n",
            "Epoch 41/50\n",
            "459/459 [==============================] - 0s 114us/sample - loss: 1.5961 - accuracy: 0.2593 - val_loss: 1.6093 - val_accuracy: 0.2568\n",
            "Epoch 42/50\n",
            "459/459 [==============================] - 0s 98us/sample - loss: 1.5955 - accuracy: 0.2614 - val_loss: 1.6091 - val_accuracy: 0.2459\n",
            "Epoch 43/50\n",
            "459/459 [==============================] - 0s 105us/sample - loss: 1.5947 - accuracy: 0.2658 - val_loss: 1.6086 - val_accuracy: 0.2186\n",
            "Epoch 44/50\n",
            "459/459 [==============================] - 0s 98us/sample - loss: 1.5947 - accuracy: 0.2723 - val_loss: 1.6088 - val_accuracy: 0.2459\n",
            "Epoch 45/50\n",
            "459/459 [==============================] - 0s 102us/sample - loss: 1.5935 - accuracy: 0.2527 - val_loss: 1.6091 - val_accuracy: 0.2514\n",
            "Epoch 46/50\n",
            "459/459 [==============================] - 0s 94us/sample - loss: 1.5931 - accuracy: 0.2745 - val_loss: 1.6096 - val_accuracy: 0.2240\n",
            "Epoch 47/50\n",
            "459/459 [==============================] - 0s 95us/sample - loss: 1.5927 - accuracy: 0.2505 - val_loss: 1.6099 - val_accuracy: 0.2295\n",
            "Epoch 48/50\n",
            "459/459 [==============================] - 0s 109us/sample - loss: 1.5923 - accuracy: 0.2702 - val_loss: 1.6101 - val_accuracy: 0.2240\n",
            "Epoch 49/50\n",
            "459/459 [==============================] - 0s 103us/sample - loss: 1.5920 - accuracy: 0.2658 - val_loss: 1.6098 - val_accuracy: 0.2404\n",
            "Epoch 50/50\n",
            "459/459 [==============================] - 0s 106us/sample - loss: 1.5918 - accuracy: 0.2484 - val_loss: 1.6100 - val_accuracy: 0.2131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlo9hZQUAV8Z",
        "colab_type": "text"
      },
      "source": [
        "MODEL BUILDING CNN, RNN, AND LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdDLnxuuQgHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(1000, 16),\n",
        "      tf.keras.layers.Conv1D(128, 5, activation = 'relu'),\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "      tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(16, activation ='relu'),\n",
        "      tf.keras.layers.Dense(5, activation='softmax')\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJh5OhmZR4S2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1f0ee515-dc10-4875-c2de-d76ea6569ccc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          16000     \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, None, 128)         10368     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 85        \n",
            "=================================================================\n",
            "Total params: 35,749\n",
            "Trainable params: 35,749\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn5SQbSGR7Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Embedding\n",
        "from tensorflow.python.keras.layers import Conv1D\n",
        "from tensorflow.python.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1CaznCWqIam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model(layers, units, num_classes):\n",
        "  \"\"\" create an instance of CNN model. \n",
        "\n",
        "      # Arguments\n",
        "          layers: int, number of `Dense` layers in the model.\n",
        "          units: int, output dimension of the layers.\n",
        "          dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "          num_classes: int, number of output classes.\n",
        "\n",
        "      # Returns\n",
        "          A CNN model instance.\n",
        "\n",
        "  \"\"\"\n",
        "  op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "  model = models.Sequential()\n",
        "  model.add(Embedding(1000, 16))\n",
        "  model.add(Conv1D(64, 5, activation = 'relu'))\n",
        "  model.add(GlobalAveragePooling1D())\n",
        "    \n",
        "  for i in range(layers-1):\n",
        "    model.add(Dense(units = units, activation ='relu'))\n",
        "    #model.add(Dropout(rate = dropout_rate))\n",
        "    units = units//2\n",
        "\n",
        "  model.add(Dense(units=op_units, activation=op_activation))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOR2iqgASaWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = 4\n",
        "units = 256\n",
        "dropout_rate = 0.1\n",
        "#input_shape = 1\n",
        "num_classes = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC_Y1_E1O036",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = cnn_model(layers, units, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfJHoK5GPDfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer = 'adam', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONQ79ts-Stap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f0099226-4832-4230-8b3f-16eeb23d3dc7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 16)          16000     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, None, 64)          5184      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 79,301\n",
            "Trainable params: 79,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kNZ4jo4O5C-",
        "colab_type": "code",
        "outputId": "1a1d7c75-4a79-41ca-9789-1f47df9b0ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "NUM_EPOCHS = 50\n",
        "history = model.fit(train_vec, training_labels,\n",
        "                    validation_data = (val_vec, validation_labels),\n",
        "                    epochs = NUM_EPOCHS, \n",
        "                    callbacks = [checkpoint, callbacks])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/50\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 1.6111 - accuracy: 0.1983 - val_loss: 1.6093 - val_accuracy: 0.2077\n",
            "Epoch 2/50\n",
            "459/459 [==============================] - 0s 237us/sample - loss: 1.6103 - accuracy: 0.1634 - val_loss: 1.6094 - val_accuracy: 0.2077\n",
            "Epoch 3/50\n",
            "459/459 [==============================] - 0s 245us/sample - loss: 1.6096 - accuracy: 0.1961 - val_loss: 1.6093 - val_accuracy: 0.1913\n",
            "Epoch 4/50\n",
            "459/459 [==============================] - 0s 232us/sample - loss: 1.6097 - accuracy: 0.1721 - val_loss: 1.6089 - val_accuracy: 0.2131\n",
            "Epoch 5/50\n",
            "459/459 [==============================] - 0s 234us/sample - loss: 1.6091 - accuracy: 0.2092 - val_loss: 1.6083 - val_accuracy: 0.2350\n",
            "Epoch 6/50\n",
            "459/459 [==============================] - 0s 234us/sample - loss: 1.6048 - accuracy: 0.2723 - val_loss: 1.6036 - val_accuracy: 0.2623\n",
            "Epoch 7/50\n",
            "459/459 [==============================] - 0s 246us/sample - loss: 1.5699 - accuracy: 0.2898 - val_loss: 1.5758 - val_accuracy: 0.2186\n",
            "Epoch 8/50\n",
            "459/459 [==============================] - 0s 218us/sample - loss: 1.4686 - accuracy: 0.3246 - val_loss: 1.5738 - val_accuracy: 0.2732\n",
            "Epoch 9/50\n",
            "459/459 [==============================] - 0s 242us/sample - loss: 1.3423 - accuracy: 0.3791 - val_loss: 1.7058 - val_accuracy: 0.2732\n",
            "Epoch 10/50\n",
            "459/459 [==============================] - 0s 251us/sample - loss: 1.1909 - accuracy: 0.4619 - val_loss: 1.6552 - val_accuracy: 0.3169\n",
            "Epoch 11/50\n",
            "459/459 [==============================] - 0s 229us/sample - loss: 0.9830 - accuracy: 0.5730 - val_loss: 1.8816 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "459/459 [==============================] - 0s 242us/sample - loss: 0.8158 - accuracy: 0.5969 - val_loss: 2.1785 - val_accuracy: 0.3443\n",
            "Epoch 13/50\n",
            "459/459 [==============================] - 0s 218us/sample - loss: 0.6914 - accuracy: 0.6688 - val_loss: 2.5586 - val_accuracy: 0.3443\n",
            "Epoch 14/50\n",
            "459/459 [==============================] - 0s 229us/sample - loss: 0.6013 - accuracy: 0.6993 - val_loss: 2.6279 - val_accuracy: 0.3880\n",
            "Epoch 15/50\n",
            "459/459 [==============================] - 0s 238us/sample - loss: 0.5292 - accuracy: 0.7211 - val_loss: 2.9687 - val_accuracy: 0.4098\n",
            "Epoch 16/50\n",
            "459/459 [==============================] - 0s 250us/sample - loss: 0.4545 - accuracy: 0.7778 - val_loss: 3.1866 - val_accuracy: 0.4481\n",
            "Epoch 17/50\n",
            "459/459 [==============================] - 0s 227us/sample - loss: 0.3758 - accuracy: 0.8344 - val_loss: 3.5763 - val_accuracy: 0.3661\n",
            "Epoch 18/50\n",
            "459/459 [==============================] - 0s 902us/sample - loss: 0.3328 - accuracy: 0.8453 - val_loss: 3.6818 - val_accuracy: 0.4699\n",
            "Epoch 19/50\n",
            "459/459 [==============================] - 0s 357us/sample - loss: 0.2651 - accuracy: 0.8845 - val_loss: 4.0580 - val_accuracy: 0.4809\n",
            "Epoch 20/50\n",
            "459/459 [==============================] - 0s 245us/sample - loss: 0.2375 - accuracy: 0.8911 - val_loss: 4.3644 - val_accuracy: 0.4590\n",
            "Epoch 21/50\n",
            "459/459 [==============================] - 0s 226us/sample - loss: 0.1763 - accuracy: 0.9368 - val_loss: 4.8093 - val_accuracy: 0.4426\n",
            "Epoch 22/50\n",
            "459/459 [==============================] - 0s 250us/sample - loss: 0.1593 - accuracy: 0.9237 - val_loss: 4.8709 - val_accuracy: 0.4699\n",
            "Epoch 23/50\n",
            "352/459 [======================>.......] - ETA: 0s - loss: 0.1083 - accuracy: 0.9744\n",
            "Reach accuracy of 95% and stop training!\n",
            "459/459 [==============================] - 0s 232us/sample - loss: 0.1119 - accuracy: 0.9717 - val_loss: 5.2841 - val_accuracy: 0.4645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SwLGxV7rrG8",
        "colab_type": "text"
      },
      "source": [
        "MODEL PERFORMANCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b-jwoaTjOy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRHVCIxIjP84",
        "colab_type": "code",
        "outputId": "e9bb68c4-28f6-47c5-b6b9-1eaf6aec4649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4dqPcXIjvyX",
        "colab_type": "code",
        "outputId": "d8b9b0d0-129e-4bed-8b00-10c3b6832ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n01LSb9an+QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjwZhxfNw38y",
        "colab_type": "text"
      },
      "source": [
        "USE SINGLE LAYER LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7rOD3KWxc5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(1000, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkOuU8JLxiX5",
        "colab_type": "code",
        "outputId": "5fab0402-7f87-4956-8581-6a7c7b4d275b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               66048     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 138,629\n",
            "Trainable params: 138,629\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi39j1snYpg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFsQksEJUEeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_1l(layers, units, lstm_layer, num_classes):\n",
        "  \"\"\"create an instance of a single layer LSTM. \n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        A single layer LSTM model instance.\n",
        "  \"\"\"\n",
        "  op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "  model = models.Sequential()\n",
        "  model.add(Embedding(1000, 16))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(lstm_layer)))\n",
        "\n",
        "    \n",
        "  for i in range(layers-1):\n",
        "    model.add(Dense(units = units, activation ='relu'))\n",
        "    #model.add(Dropout(rate = dropout_rate))\n",
        "    units = units//2\n",
        "\n",
        "  model.add(Dense(units=op_units, activation=op_activation))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj4w9PstYSY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = 4\n",
        "units = 256\n",
        "dropout_rate = 0.1\n",
        "#input_shape = 1\n",
        "lstm_layer = 64\n",
        "num_classes = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQUL6_3zYTWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = lstm_1l(layers, units, lstm_layer, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDF40ZTcZR6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4cbfdd32-fbe3-4935-fd8b-83eb2bd296a2"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 16)          16000     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               41472     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 131,973\n",
            "Trainable params: 131,973\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd7x8SAExkDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1sQZeNExqEP",
        "colab_type": "code",
        "outputId": "1fc45fdf-5b0c-46f6-ccc5-b9af52ed57c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "model1.fit(train_vec, training_labels,\n",
        "          validation_data=(val_vec, validation_labels),\n",
        "          epochs=50, \n",
        "          callbacks = [ callbacks])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/50\n",
            "459/459 [==============================] - 5s 10ms/sample - loss: 1.6103 - accuracy: 0.1743 - val_loss: 1.6095 - val_accuracy: 0.1858\n",
            "Epoch 2/50\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 1.6094 - accuracy: 0.2113 - val_loss: 1.6085 - val_accuracy: 0.2022\n",
            "Epoch 3/50\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 1.6063 - accuracy: 0.2288 - val_loss: 1.6011 - val_accuracy: 0.3169\n",
            "Epoch 4/50\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 1.5735 - accuracy: 0.4161 - val_loss: 1.5660 - val_accuracy: 0.2350\n",
            "Epoch 5/50\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 1.4151 - accuracy: 0.4336 - val_loss: 1.4191 - val_accuracy: 0.3607\n",
            "Epoch 6/50\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 1.0290 - accuracy: 0.5643 - val_loss: 1.3994 - val_accuracy: 0.4153\n",
            "Epoch 7/50\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 0.7222 - accuracy: 0.6819 - val_loss: 1.5657 - val_accuracy: 0.4317\n",
            "Epoch 8/50\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 0.5221 - accuracy: 0.8039 - val_loss: 1.7138 - val_accuracy: 0.4536\n",
            "Epoch 9/50\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 0.3089 - accuracy: 0.9041 - val_loss: 2.1746 - val_accuracy: 0.4699\n",
            "Epoch 10/50\n",
            "416/459 [==========================>...] - ETA: 0s - loss: 0.1416 - accuracy: 0.9760\n",
            "Reach accuracy of 95% and stop training!\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 0.1404 - accuracy: 0.9739 - val_loss: 2.6601 - val_accuracy: 0.4809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd90b8237b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToxroTOZy3Az",
        "colab_type": "text"
      },
      "source": [
        "USE MULTIPLE LAYER LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtvqCYMny1Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(1000, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly8VAdY0y9FE",
        "colab_type": "code",
        "outputId": "645da3f9-8ccf-4bfb-be3a-bbc49d254c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 128)         66048     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 85        \n",
            "=================================================================\n",
            "Total params: 176,549\n",
            "Trainable params: 176,549\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IQivKPJzIeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__h1ykqqy_Iz",
        "colab_type": "code",
        "outputId": "ec9e05c3-4f45-4fdd-ab15-8ec73ff36cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "model2.fit(train_vec, training_labels,\n",
        "           validation_data=(val_vec, validation_labels),\n",
        "           epochs=30, \n",
        "           callbacks = [ callbacks])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/30\n",
            "459/459 [==============================] - 7s 15ms/sample - loss: 1.6100 - accuracy: 0.2026 - val_loss: 1.6082 - val_accuracy: 0.2131\n",
            "Epoch 2/30\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 1.6080 - accuracy: 0.2048 - val_loss: 1.6060 - val_accuracy: 0.2295\n",
            "Epoch 3/30\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 1.5995 - accuracy: 0.2941 - val_loss: 1.5953 - val_accuracy: 0.2896\n",
            "Epoch 4/30\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 1.5403 - accuracy: 0.3682 - val_loss: 1.5020 - val_accuracy: 0.3060\n",
            "Epoch 5/30\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 1.2583 - accuracy: 0.4183 - val_loss: 1.5028 - val_accuracy: 0.4098\n",
            "Epoch 6/30\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 1.0714 - accuracy: 0.5839 - val_loss: 1.4754 - val_accuracy: 0.4317\n",
            "Epoch 7/30\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 0.8174 - accuracy: 0.7364 - val_loss: 1.6724 - val_accuracy: 0.3825\n",
            "Epoch 8/30\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 0.5424 - accuracy: 0.8192 - val_loss: 1.8211 - val_accuracy: 0.4645\n",
            "Epoch 9/30\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 0.4052 - accuracy: 0.8998 - val_loss: 1.8904 - val_accuracy: 0.5082\n",
            "Epoch 10/30\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 0.2465 - accuracy: 0.9368 - val_loss: 1.9198 - val_accuracy: 0.5246\n",
            "Epoch 11/30\n",
            "416/459 [==========================>...] - ETA: 0s - loss: 0.1406 - accuracy: 0.9591\n",
            "Reach accuracy of 95% and stop training!\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 0.1427 - accuracy: 0.9608 - val_loss: 2.2927 - val_accuracy: 0.4973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb4b21f6630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgzBEyX2zb_V",
        "colab_type": "text"
      },
      "source": [
        "USE GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMer-IAAzeCs",
        "colab_type": "code",
        "outputId": "d2f4a101-fdac-426a-9999-fb37ea16d3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(1000, 64, input_length=24),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "model3.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 24, 64)            64000     \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 64)                18816     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 6)                 390       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 35        \n",
            "=================================================================\n",
            "Total params: 83,241\n",
            "Trainable params: 83,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BspZTqB7z9jY",
        "colab_type": "code",
        "outputId": "f4cd6942-b7aa-46c7-e099-8e8151855f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "model3.fit(training_data, training_labels,\n",
        "                    validation_data=(test_data, test_labels),\n",
        "                    epochs=30, \n",
        "                    callbacks = [ callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 524 samples, validate on 130 samples\n",
            "Epoch 1/30\n",
            "524/524 [==============================] - 4s 7ms/sample - loss: 1.6102 - accuracy: 0.2099 - val_loss: 1.6057 - val_accuracy: 0.2462\n",
            "Epoch 2/30\n",
            "524/524 [==============================] - 0s 662us/sample - loss: 1.5952 - accuracy: 0.2538 - val_loss: 1.6034 - val_accuracy: 0.2000\n",
            "Epoch 3/30\n",
            "524/524 [==============================] - 0s 628us/sample - loss: 1.5684 - accuracy: 0.2309 - val_loss: 1.5907 - val_accuracy: 0.2308\n",
            "Epoch 4/30\n",
            "524/524 [==============================] - 0s 686us/sample - loss: 1.5167 - accuracy: 0.2653 - val_loss: 1.5860 - val_accuracy: 0.2231\n",
            "Epoch 5/30\n",
            "524/524 [==============================] - 0s 658us/sample - loss: 1.4132 - accuracy: 0.3588 - val_loss: 1.6173 - val_accuracy: 0.3231\n",
            "Epoch 6/30\n",
            "524/524 [==============================] - 0s 630us/sample - loss: 1.2616 - accuracy: 0.4866 - val_loss: 1.5625 - val_accuracy: 0.3538\n",
            "Epoch 7/30\n",
            "524/524 [==============================] - 0s 637us/sample - loss: 1.0967 - accuracy: 0.6069 - val_loss: 1.7247 - val_accuracy: 0.3154\n",
            "Epoch 8/30\n",
            "524/524 [==============================] - 0s 674us/sample - loss: 0.9403 - accuracy: 0.6947 - val_loss: 1.7436 - val_accuracy: 0.3000\n",
            "Epoch 9/30\n",
            "524/524 [==============================] - 0s 642us/sample - loss: 0.7923 - accuracy: 0.8053 - val_loss: 1.7286 - val_accuracy: 0.3231\n",
            "Epoch 10/30\n",
            "524/524 [==============================] - 0s 636us/sample - loss: 0.6634 - accuracy: 0.8492 - val_loss: 1.8570 - val_accuracy: 0.3000\n",
            "Epoch 11/30\n",
            "524/524 [==============================] - 0s 623us/sample - loss: 0.4920 - accuracy: 0.8989 - val_loss: 1.8777 - val_accuracy: 0.3231\n",
            "Epoch 12/30\n",
            "512/524 [============================>.] - ETA: 0s - loss: 0.3568 - accuracy: 0.9492\n",
            "Reach accuracy of 95% and stop training!\n",
            "524/524 [==============================] - 0s 640us/sample - loss: 0.3551 - accuracy: 0.9504 - val_loss: 1.9236 - val_accuracy: 0.3538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9580861c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMXrnsq3vKbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clear the trained models\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}