{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "191216TF_IPIP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhuang12/Tensorflow-for-personality-items-classification/blob/master/191216TF_IPIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52bYMFnQprcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THIS NOTEBOOK WAS CREATED TO USE TF NLP FOR IPIP ITEMS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkBl41YZNuzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HmQPn2QLInf",
        "colab_type": "code",
        "outputId": "3c32791b-846b-4100-93f4-f632c0eb3451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Di92YMtLRR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "8b4405fb-9fa4-4e2b-ceaa-6b2646be3d90"
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (42.0.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVnl38Ttp19e",
        "colab_type": "text"
      },
      "source": [
        "DATA LOADING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WLvGKL-p1Qx",
        "colab_type": "code",
        "outputId": "05ad58b4-e882-46b0-a760-5deddb56cafb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWPpXW6IMU24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dpath = os.path.join(r\"C:/Users/amead/Google Drive/active/machine learning/big5/big_five_items.csv\")\n",
        "dpath = os.path.join(\"/content/drive/My Drive/big_five_items.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XVQVhbQMw-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(dpath,low_memory = False, sep = \"\\t\", lineterminator = '\\n', encoding = 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTEs9VUUO6RB",
        "colab_type": "text"
      },
      "source": [
        "DATA PROCESSING\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82XZ2o3yO_ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stem as one string\n",
        "sentences = pd.Series(data['Stem'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3g2CgyHRu4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scale as categorical data\n",
        "data['labels'] = data['Scale'].astype('category').cat.codes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJJoFen1Uj03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make the labels into np.array\n",
        "labels = np.array(pd.Series(data['labels']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp0mlKadp8x8",
        "colab_type": "text"
      },
      "source": [
        "DATA CLEANING (STEMMING)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjR16yfrWvZ5",
        "colab_type": "text"
      },
      "source": [
        "TOKENIZATION AND PADDING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djKwOT6_mPVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "random.seed(700)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjsXQIDLp3WR",
        "colab": {}
      },
      "source": [
        "#stratified random sampling training and validation sample by dimensions\n",
        "\n",
        "training_data = []\n",
        "training_labels = []\n",
        "validation_data = []\n",
        "validation_labels = []\n",
        "\n",
        "for s in range(5):\n",
        "  training_set = data.loc[data['labels'] == s, 'Stem'].sample(frac = 0.7, replace = False, random_state = 1)\n",
        "  training_l = np.array([s]*len(training_set))\n",
        "\n",
        "  validation_set = data.loc[(~data['Stem'].isin(training_set)) & (data['labels'] == s), 'Stem']\n",
        "  validation_l = np.array([s]*len(validation_set))\n",
        "\n",
        "  training_data.extend(training_set)\n",
        "  training_labels.extend(training_l)\n",
        "\n",
        "  validation_data.extend(validation_set)\n",
        "  validation_labels.extend(validation_l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySUmrKW22KE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LENGTH = 10000\n",
        "\n",
        "def sequence_vectorization (train_texts, val_texts): \n",
        "  \"\"\"Vectorizes texts as sequence vectors.\n",
        "\n",
        "    1 text = 1 sequence vector with fixed length.\n",
        "\n",
        "    # Arguments\n",
        "        train_texts: list, training text strings.\n",
        "        val_texts: list, validation text strings.\n",
        "\n",
        "    # Returns\n",
        "        x_train, x_val, word_index: vectorized training and validation\n",
        "            texts and word index dictionary.\n",
        "  \"\"\"\n",
        "  tokenizer = Tokenizer(oov_token = \"<OOV>\", num_words = MAX_LENGTH)\n",
        "  # Create vocabulary with training texts.\n",
        "  tokenizer.fit_on_texts(train_texts)\n",
        "  x_train = tokenizer.texts_to_sequences(train_texts)\n",
        "  x_val = tokenizer.texts_to_sequences(val_texts)\n",
        "  \n",
        "  # Get max sequence length.\n",
        "  max_length = len(max(x_train, key=len))\n",
        "  \n",
        "  if max_length > MAX_LENGTH:\n",
        "    max_length = MAX_LENGTH\n",
        " \n",
        "# Fix sequence length to max value. Sequences shorter than the length are\n",
        "# padded in the beginning and sequences longer are truncated\n",
        "# at the beginning.\n",
        "  x_train = np.asarray(pad_sequences(x_train, maxlen=max_length))\n",
        "  x_val = np.asarray(pad_sequences(x_val, maxlen=max_length))\n",
        "\n",
        "  return x_train, x_val, tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUCHHm7xj2p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_vec, val_vec, word_index = sequence_vectorization(training_data, validation_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FOHOH_wInpCw",
        "colab": {}
      },
      "source": [
        "training_labels = np.array(training_labels)\n",
        "validation_labels = np.array(validation_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC-s3jc7qH8Q",
        "colab_type": "text"
      },
      "source": [
        "MODEL BUILING - MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pPj0LZjZkXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a callback criteria\n",
        "ACCURACY_STOP = 0.95\n",
        "\n",
        "class myCallbacks(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if (logs.get('accuracy')> ACCURACY_STOP):\n",
        "      self.model.stop_training = True\n",
        "      print(\"\\nReach accuracy of 95% and stop training!\")\n",
        "\n",
        "callbacks = myCallbacks()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGnjMaSYn1V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create checkponts to \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def checkpoint(model_name):\n",
        "  checkpoint_directory = '/content/drive/My Drive/NLP_tensorflow/{}'.format(model_name)\n",
        "\n",
        "  checkpoint = ModelCheckpoint(checkpoint_directory,\n",
        "                             monitor = \"val_accuracy\", \n",
        "                             save_best_only = True, \n",
        "                             mode = 'max')\n",
        "  return checkpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-x9yGNwAUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_last_layer_units_and_activation(num_classes):\n",
        "    \"\"\"Gets the # units and activation function for the last network layer.\n",
        "\n",
        "    # Arguments\n",
        "        num_classes: int, number of classes.\n",
        "\n",
        "    # Returns\n",
        "        units, activation values.\n",
        "    \"\"\"\n",
        "    if num_classes == 2:\n",
        "        activation = 'sigmoid'\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = 'softmax'\n",
        "        units = num_classes\n",
        "    return units, activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWnbP6Iupcn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list parameters for different models\n",
        "layers = 4\n",
        "units = 12\n",
        "#dropout_rate = 0.1 -- could play with\n",
        "num_classes = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y_7yzwQHI_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4IqBtVJAkOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_model(layers, units, num_classes):\n",
        "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        #dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        An MLP model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "    #model.add(Dropout(rate = dropout_rate)\n",
        "    \n",
        "    for i in range(layers-1):\n",
        "      model.add(Dense(units = units, activation = 'relu'))\n",
        "      #model.add(Dropout(rate = dropout_rate))\n",
        "\n",
        "    model.add(Dense(units = op_units, activation = op_activation))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCtGDpPIA0ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_model = mlp_model(layers, units, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWW8utx3HOs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer = 'adam', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tTcnJsKHker",
        "colab_type": "code",
        "outputId": "35aa78de-3812-410e-989c-7eecef7ca517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "NUM_EPOCHS = 50\n",
        "model_name = 'mlp.h5'  \n",
        "\n",
        "mlp_history = mlp_model.fit(train_vec, training_labels,\n",
        "                    validation_data = (val_vec, validation_labels),\n",
        "                    epochs = NUM_EPOCHS, \n",
        "                    callbacks = [checkpoint(model_name), callbacks])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/50\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 23.1935 - accuracy: 0.1874 - val_loss: 11.7204 - val_accuracy: 0.1858\n",
            "Epoch 2/50\n",
            "459/459 [==============================] - 0s 99us/sample - loss: 11.5599 - accuracy: 0.2070 - val_loss: 6.4660 - val_accuracy: 0.1803\n",
            "Epoch 3/50\n",
            "459/459 [==============================] - 0s 139us/sample - loss: 6.8368 - accuracy: 0.2288 - val_loss: 4.0308 - val_accuracy: 0.2077\n",
            "Epoch 4/50\n",
            "459/459 [==============================] - 0s 179us/sample - loss: 4.7590 - accuracy: 0.2026 - val_loss: 2.7779 - val_accuracy: 0.2295\n",
            "Epoch 5/50\n",
            "459/459 [==============================] - 0s 148us/sample - loss: 3.3332 - accuracy: 0.1983 - val_loss: 2.2544 - val_accuracy: 0.2568\n",
            "Epoch 6/50\n",
            "459/459 [==============================] - 0s 134us/sample - loss: 2.6454 - accuracy: 0.1895 - val_loss: 1.9769 - val_accuracy: 0.2623\n",
            "Epoch 7/50\n",
            "459/459 [==============================] - 0s 160us/sample - loss: 2.2104 - accuracy: 0.1917 - val_loss: 1.8097 - val_accuracy: 0.2732\n",
            "Epoch 8/50\n",
            "459/459 [==============================] - 0s 96us/sample - loss: 1.9516 - accuracy: 0.1852 - val_loss: 1.7498 - val_accuracy: 0.2568\n",
            "Epoch 9/50\n",
            "459/459 [==============================] - 0s 87us/sample - loss: 1.8428 - accuracy: 0.1874 - val_loss: 1.7310 - val_accuracy: 0.2459\n",
            "Epoch 10/50\n",
            "459/459 [==============================] - 0s 91us/sample - loss: 1.7843 - accuracy: 0.1961 - val_loss: 1.7065 - val_accuracy: 0.2295\n",
            "Epoch 11/50\n",
            "459/459 [==============================] - 0s 80us/sample - loss: 1.7425 - accuracy: 0.1983 - val_loss: 1.7118 - val_accuracy: 0.2404\n",
            "Epoch 12/50\n",
            "459/459 [==============================] - 0s 78us/sample - loss: 1.7112 - accuracy: 0.1961 - val_loss: 1.6891 - val_accuracy: 0.2404\n",
            "Epoch 13/50\n",
            "459/459 [==============================] - 0s 91us/sample - loss: 1.6894 - accuracy: 0.1961 - val_loss: 1.6653 - val_accuracy: 0.2295\n",
            "Epoch 14/50\n",
            "459/459 [==============================] - 0s 87us/sample - loss: 1.6654 - accuracy: 0.1983 - val_loss: 1.6567 - val_accuracy: 0.2240\n",
            "Epoch 15/50\n",
            "459/459 [==============================] - 0s 92us/sample - loss: 1.6460 - accuracy: 0.1961 - val_loss: 1.6502 - val_accuracy: 0.2240\n",
            "Epoch 16/50\n",
            "459/459 [==============================] - 0s 81us/sample - loss: 1.6359 - accuracy: 0.1961 - val_loss: 1.6448 - val_accuracy: 0.2240\n",
            "Epoch 17/50\n",
            "459/459 [==============================] - 0s 87us/sample - loss: 1.6275 - accuracy: 0.1961 - val_loss: 1.6382 - val_accuracy: 0.2077\n",
            "Epoch 18/50\n",
            "459/459 [==============================] - 0s 96us/sample - loss: 1.6223 - accuracy: 0.1939 - val_loss: 1.6355 - val_accuracy: 0.2022\n",
            "Epoch 19/50\n",
            "459/459 [==============================] - 0s 77us/sample - loss: 1.6186 - accuracy: 0.1983 - val_loss: 1.6309 - val_accuracy: 0.2022\n",
            "Epoch 20/50\n",
            "459/459 [==============================] - 0s 82us/sample - loss: 1.6160 - accuracy: 0.2004 - val_loss: 1.6297 - val_accuracy: 0.2022\n",
            "Epoch 21/50\n",
            "459/459 [==============================] - 0s 86us/sample - loss: 1.6127 - accuracy: 0.2004 - val_loss: 1.6274 - val_accuracy: 0.2022\n",
            "Epoch 22/50\n",
            "459/459 [==============================] - 0s 81us/sample - loss: 1.6100 - accuracy: 0.2004 - val_loss: 1.6263 - val_accuracy: 0.2022\n",
            "Epoch 23/50\n",
            "459/459 [==============================] - 0s 80us/sample - loss: 1.6073 - accuracy: 0.2004 - val_loss: 1.6259 - val_accuracy: 0.2131\n",
            "Epoch 24/50\n",
            "459/459 [==============================] - 0s 90us/sample - loss: 1.6046 - accuracy: 0.2004 - val_loss: 1.6254 - val_accuracy: 0.2240\n",
            "Epoch 25/50\n",
            "459/459 [==============================] - 0s 80us/sample - loss: 1.6020 - accuracy: 0.2004 - val_loss: 1.6210 - val_accuracy: 0.2186\n",
            "Epoch 26/50\n",
            "459/459 [==============================] - 0s 90us/sample - loss: 1.6009 - accuracy: 0.2026 - val_loss: 1.6231 - val_accuracy: 0.2240\n",
            "Epoch 27/50\n",
            "459/459 [==============================] - 0s 85us/sample - loss: 1.5983 - accuracy: 0.2070 - val_loss: 1.6213 - val_accuracy: 0.2240\n",
            "Epoch 28/50\n",
            "459/459 [==============================] - 0s 84us/sample - loss: 1.5975 - accuracy: 0.2092 - val_loss: 1.6226 - val_accuracy: 0.2186\n",
            "Epoch 29/50\n",
            "459/459 [==============================] - 0s 83us/sample - loss: 1.5974 - accuracy: 0.2092 - val_loss: 1.6214 - val_accuracy: 0.2186\n",
            "Epoch 30/50\n",
            "459/459 [==============================] - 0s 83us/sample - loss: 1.5972 - accuracy: 0.2092 - val_loss: 1.6235 - val_accuracy: 0.2240\n",
            "Epoch 31/50\n",
            "459/459 [==============================] - 0s 75us/sample - loss: 1.5975 - accuracy: 0.2048 - val_loss: 1.6193 - val_accuracy: 0.2131\n",
            "Epoch 32/50\n",
            "459/459 [==============================] - 0s 81us/sample - loss: 1.5964 - accuracy: 0.2070 - val_loss: 1.6203 - val_accuracy: 0.2131\n",
            "Epoch 33/50\n",
            "459/459 [==============================] - 0s 81us/sample - loss: 1.5962 - accuracy: 0.2070 - val_loss: 1.6202 - val_accuracy: 0.2131\n",
            "Epoch 34/50\n",
            "459/459 [==============================] - 0s 78us/sample - loss: 1.5959 - accuracy: 0.2070 - val_loss: 1.6212 - val_accuracy: 0.2131\n",
            "Epoch 35/50\n",
            "459/459 [==============================] - 0s 78us/sample - loss: 1.5956 - accuracy: 0.2070 - val_loss: 1.6226 - val_accuracy: 0.2131\n",
            "Epoch 36/50\n",
            "459/459 [==============================] - 0s 89us/sample - loss: 1.5956 - accuracy: 0.2070 - val_loss: 1.6240 - val_accuracy: 0.2131\n",
            "Epoch 37/50\n",
            "459/459 [==============================] - 0s 101us/sample - loss: 1.5955 - accuracy: 0.2092 - val_loss: 1.6237 - val_accuracy: 0.2131\n",
            "Epoch 38/50\n",
            "459/459 [==============================] - 0s 100us/sample - loss: 1.5958 - accuracy: 0.2070 - val_loss: 1.6247 - val_accuracy: 0.2131\n",
            "Epoch 39/50\n",
            "459/459 [==============================] - 0s 79us/sample - loss: 1.5952 - accuracy: 0.2070 - val_loss: 1.6243 - val_accuracy: 0.2131\n",
            "Epoch 40/50\n",
            "459/459 [==============================] - 0s 82us/sample - loss: 1.5952 - accuracy: 0.2070 - val_loss: 1.6230 - val_accuracy: 0.2131\n",
            "Epoch 41/50\n",
            "459/459 [==============================] - 0s 83us/sample - loss: 1.5949 - accuracy: 0.2070 - val_loss: 1.6238 - val_accuracy: 0.2131\n",
            "Epoch 42/50\n",
            "459/459 [==============================] - 0s 86us/sample - loss: 1.5949 - accuracy: 0.2048 - val_loss: 1.6261 - val_accuracy: 0.2131\n",
            "Epoch 43/50\n",
            "459/459 [==============================] - 0s 100us/sample - loss: 1.5947 - accuracy: 0.2070 - val_loss: 1.6268 - val_accuracy: 0.2131\n",
            "Epoch 44/50\n",
            "459/459 [==============================] - 0s 92us/sample - loss: 1.5944 - accuracy: 0.2070 - val_loss: 1.6263 - val_accuracy: 0.2131\n",
            "Epoch 45/50\n",
            "459/459 [==============================] - 0s 92us/sample - loss: 1.5944 - accuracy: 0.2070 - val_loss: 1.6264 - val_accuracy: 0.2131\n",
            "Epoch 46/50\n",
            "459/459 [==============================] - 0s 85us/sample - loss: 1.5944 - accuracy: 0.2070 - val_loss: 1.6276 - val_accuracy: 0.2131\n",
            "Epoch 47/50\n",
            "459/459 [==============================] - 0s 83us/sample - loss: 1.5940 - accuracy: 0.2092 - val_loss: 1.6287 - val_accuracy: 0.2131\n",
            "Epoch 48/50\n",
            "459/459 [==============================] - 0s 86us/sample - loss: 1.5934 - accuracy: 0.2092 - val_loss: 1.6285 - val_accuracy: 0.2131\n",
            "Epoch 49/50\n",
            "459/459 [==============================] - 0s 83us/sample - loss: 1.5930 - accuracy: 0.2092 - val_loss: 1.6292 - val_accuracy: 0.2131\n",
            "Epoch 50/50\n",
            "459/459 [==============================] - 0s 79us/sample - loss: 1.5928 - accuracy: 0.2092 - val_loss: 1.6301 - val_accuracy: 0.2131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlo9hZQUAV8Z",
        "colab_type": "text"
      },
      "source": [
        "MODEL BUILDING CNN, RNN, AND LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5iYo3M5rYUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#general function inputs\n",
        "layers = 4\n",
        "units = 256\n",
        "dropout_rate = 0.1\n",
        "#input_shape = 1\n",
        "num_classes = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJFBZB8fsEy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cnn model related inputs \n",
        "embedding_input = 1000\n",
        "embedding_output = 16\n",
        "conv1d_filter = 64\n",
        "conv1d_kernel_size = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn5SQbSGR7Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Embedding\n",
        "from tensorflow.python.keras.layers import Conv1D\n",
        "from tensorflow.python.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1CaznCWqIam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model(layers, units, num_classes):\n",
        "  \"\"\" create an instance of CNN model. \n",
        "\n",
        "      # Arguments\n",
        "          layers: int, number of `Dense` layers in the model.\n",
        "          units: int, output dimension of the layers.\n",
        "          #dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "          num_classes: int, number of output classes.\n",
        "\n",
        "      # Returns\n",
        "          A CNN model instance.\n",
        "\n",
        "  \"\"\"\n",
        "  op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "  model = models.Sequential()\n",
        "  model.add(Embedding(embedding_input, embedding_output))\n",
        "  model.add(Conv1D(conv1d_filter, conv1d_kernel_size, activation = 'relu'))\n",
        "  model.add(GlobalAveragePooling1D())\n",
        "    \n",
        "  for i in range(layers-1):\n",
        "    model.add(Dense(units = units, activation ='relu'))\n",
        "    #model.add(Dropout(rate = dropout_rate))\n",
        "    units = units//2\n",
        "\n",
        "  model.add(Dense(units = op_units, activation = op_activation))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC_Y1_E1O036",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = cnn_model(layers, units, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfJHoK5GPDfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer = 'adam', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONQ79ts-Stap",
        "colab_type": "code",
        "outputId": "837bc120-c570-4136-9685-3aa93715d211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 16)          16000     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, None, 64)          3136      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 77,253\n",
            "Trainable params: 77,253\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kNZ4jo4O5C-",
        "colab_type": "code",
        "outputId": "3ca7b73a-1203-4ba8-c1f9-79ce2c238d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "NUM_EPOCHS = 50\n",
        "model_name = 'cnn_model.h5'\n",
        "\n",
        "cnn_history = model.fit(train_vec, training_labels,\n",
        "                    validation_data = (val_vec, validation_labels),\n",
        "                    epochs = NUM_EPOCHS, \n",
        "                    callbacks = [checkpoint(model_name), callbacks])"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/50\n",
            "459/459 [==============================] - 1s 2ms/sample - loss: 1.6107 - accuracy: 0.1765 - val_loss: 1.6096 - val_accuracy: 0.2186\n",
            "Epoch 2/50\n",
            "459/459 [==============================] - 0s 191us/sample - loss: 1.6098 - accuracy: 0.2048 - val_loss: 1.6101 - val_accuracy: 0.1858\n",
            "Epoch 3/50\n",
            "459/459 [==============================] - 0s 192us/sample - loss: 1.6094 - accuracy: 0.2048 - val_loss: 1.6098 - val_accuracy: 0.2077\n",
            "Epoch 4/50\n",
            "459/459 [==============================] - 0s 274us/sample - loss: 1.6098 - accuracy: 0.1874 - val_loss: 1.6091 - val_accuracy: 0.2459\n",
            "Epoch 5/50\n",
            "459/459 [==============================] - 0s 179us/sample - loss: 1.6073 - accuracy: 0.2244 - val_loss: 1.6079 - val_accuracy: 0.2240\n",
            "Epoch 6/50\n",
            "459/459 [==============================] - 0s 219us/sample - loss: 1.5944 - accuracy: 0.2505 - val_loss: 1.5999 - val_accuracy: 0.2240\n",
            "Epoch 7/50\n",
            "459/459 [==============================] - 0s 179us/sample - loss: 1.5262 - accuracy: 0.2854 - val_loss: 1.5892 - val_accuracy: 0.2459\n",
            "Epoch 8/50\n",
            "459/459 [==============================] - 0s 192us/sample - loss: 1.4284 - accuracy: 0.3333 - val_loss: 1.6149 - val_accuracy: 0.2186\n",
            "Epoch 9/50\n",
            "459/459 [==============================] - 0s 252us/sample - loss: 1.3081 - accuracy: 0.3573 - val_loss: 1.6891 - val_accuracy: 0.2623\n",
            "Epoch 10/50\n",
            "459/459 [==============================] - 0s 197us/sample - loss: 1.1704 - accuracy: 0.3965 - val_loss: 1.7225 - val_accuracy: 0.2568\n",
            "Epoch 11/50\n",
            "459/459 [==============================] - 0s 246us/sample - loss: 1.0675 - accuracy: 0.4749 - val_loss: 1.9265 - val_accuracy: 0.2842\n",
            "Epoch 12/50\n",
            "459/459 [==============================] - 0s 176us/sample - loss: 0.9908 - accuracy: 0.4967 - val_loss: 2.1952 - val_accuracy: 0.2568\n",
            "Epoch 13/50\n",
            "459/459 [==============================] - 0s 193us/sample - loss: 0.9212 - accuracy: 0.5272 - val_loss: 2.4676 - val_accuracy: 0.2732\n",
            "Epoch 14/50\n",
            "459/459 [==============================] - 0s 240us/sample - loss: 0.8933 - accuracy: 0.5643 - val_loss: 2.4535 - val_accuracy: 0.3060\n",
            "Epoch 15/50\n",
            "459/459 [==============================] - 0s 170us/sample - loss: 0.8311 - accuracy: 0.6187 - val_loss: 2.5657 - val_accuracy: 0.2787\n",
            "Epoch 16/50\n",
            "459/459 [==============================] - 0s 194us/sample - loss: 0.7829 - accuracy: 0.6122 - val_loss: 2.6639 - val_accuracy: 0.2951\n",
            "Epoch 17/50\n",
            "459/459 [==============================] - 0s 187us/sample - loss: 0.7216 - accuracy: 0.6797 - val_loss: 2.9615 - val_accuracy: 0.3060\n",
            "Epoch 18/50\n",
            "459/459 [==============================] - 0s 253us/sample - loss: 0.6829 - accuracy: 0.6667 - val_loss: 3.2080 - val_accuracy: 0.3169\n",
            "Epoch 19/50\n",
            "459/459 [==============================] - 0s 255us/sample - loss: 0.6302 - accuracy: 0.7647 - val_loss: 3.3843 - val_accuracy: 0.3552\n",
            "Epoch 20/50\n",
            "459/459 [==============================] - 0s 187us/sample - loss: 0.5606 - accuracy: 0.7560 - val_loss: 3.8779 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "459/459 [==============================] - 0s 313us/sample - loss: 0.4571 - accuracy: 0.8431 - val_loss: 4.2748 - val_accuracy: 0.3716\n",
            "Epoch 22/50\n",
            "459/459 [==============================] - 0s 181us/sample - loss: 0.3897 - accuracy: 0.8606 - val_loss: 4.3304 - val_accuracy: 0.3716\n",
            "Epoch 23/50\n",
            "459/459 [==============================] - 0s 184us/sample - loss: 0.3424 - accuracy: 0.9020 - val_loss: 4.9123 - val_accuracy: 0.3716\n",
            "Epoch 24/50\n",
            "459/459 [==============================] - 0s 257us/sample - loss: 0.2931 - accuracy: 0.8976 - val_loss: 5.3721 - val_accuracy: 0.3770\n",
            "Epoch 25/50\n",
            "459/459 [==============================] - 0s 267us/sample - loss: 0.2365 - accuracy: 0.9346 - val_loss: 5.7364 - val_accuracy: 0.3989\n",
            "Epoch 26/50\n",
            "459/459 [==============================] - 0s 210us/sample - loss: 0.1984 - accuracy: 0.9412 - val_loss: 5.8609 - val_accuracy: 0.3989\n",
            "Epoch 27/50\n",
            "416/459 [==========================>...] - ETA: 0s - loss: 0.1467 - accuracy: 0.9495\n",
            "Reach accuracy of 95% and stop training!\n",
            "459/459 [==============================] - 0s 189us/sample - loss: 0.1436 - accuracy: 0.9521 - val_loss: 6.5445 - val_accuracy: 0.3934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjwZhxfNw38y",
        "colab_type": "text"
      },
      "source": [
        "USE SINGLE LAYER LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7rOD3KWxc5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(1000, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkOuU8JLxiX5",
        "colab_type": "code",
        "outputId": "5979c34f-e1f4-4a92-81d8-40ed8004168b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 128)               66048     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 138,629\n",
            "Trainable params: 138,629\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm-ECjeiuX8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lstm related inputs\n",
        "lstm_n = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi39j1snYpg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFsQksEJUEeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_1l(layers, units, lstm_n, num_classes):\n",
        "  \"\"\"create an instance of a single layer LSTM. \n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        lstm_n: int, number of neurons in the LSTM layer\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        A single layer LSTM model instance.\n",
        "  \"\"\"\n",
        "  op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "  model = models.Sequential()\n",
        "  model.add(Embedding(embedding_input, embedding_output))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(lstm_n)))\n",
        "\n",
        "  for i in range(layers-1):\n",
        "    model.add(Dense(units = units, activation ='relu'))\n",
        "    #model.add(Dropout(rate = dropout_rate))\n",
        "    units = units//2\n",
        "\n",
        "  model.add(Dense(units = op_units, activation = op_activation))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQUL6_3zYTWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lstm_1l(layers, units, lstm_n, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDF40ZTcZR6L",
        "colab_type": "code",
        "outputId": "faf1307a-b222-48d3-bf8d-e3894babedfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, None, 16)          16000     \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 128)               41472     \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 131,973\n",
            "Trainable params: 131,973\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd7x8SAExkDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1sQZeNExqEP",
        "colab_type": "code",
        "outputId": "2a5b6541-3580-4036-87a7-96fab190fa44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "model_name = 's_lstm.h5'\n",
        "single_lstm_history = model.fit(train_vec, training_labels,\n",
        "                                 validation_data=(val_vec, validation_labels),\n",
        "                                 epochs=NUM_EPOCHS,\n",
        "                                 callbacks = [checkpoint(model_name), callbacks])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/50\n",
            "459/459 [==============================] - 5s 11ms/sample - loss: 1.6106 - accuracy: 0.1699 - val_loss: 1.6092 - val_accuracy: 0.2295\n",
            "Epoch 2/50\n",
            "459/459 [==============================] - 0s 827us/sample - loss: 1.6098 - accuracy: 0.2070 - val_loss: 1.6084 - val_accuracy: 0.2131\n",
            "Epoch 3/50\n",
            "459/459 [==============================] - 0s 946us/sample - loss: 1.6082 - accuracy: 0.2375 - val_loss: 1.6073 - val_accuracy: 0.2131\n",
            "Epoch 4/50\n",
            "459/459 [==============================] - 0s 964us/sample - loss: 1.6016 - accuracy: 0.2854 - val_loss: 1.5992 - val_accuracy: 0.2787\n",
            "Epoch 5/50\n",
            "459/459 [==============================] - 0s 947us/sample - loss: 1.5499 - accuracy: 0.4379 - val_loss: 1.5255 - val_accuracy: 0.3224\n",
            "Epoch 6/50\n",
            "459/459 [==============================] - 0s 981us/sample - loss: 1.3005 - accuracy: 0.4641 - val_loss: 1.4954 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "459/459 [==============================] - 0s 954us/sample - loss: 0.9429 - accuracy: 0.6405 - val_loss: 1.6230 - val_accuracy: 0.3661\n",
            "Epoch 8/50\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.6717 - accuracy: 0.6972 - val_loss: 1.5698 - val_accuracy: 0.4809\n",
            "Epoch 9/50\n",
            "459/459 [==============================] - 0s 906us/sample - loss: 0.4523 - accuracy: 0.8410 - val_loss: 1.9159 - val_accuracy: 0.4809\n",
            "Epoch 10/50\n",
            "459/459 [==============================] - 0s 1ms/sample - loss: 0.2465 - accuracy: 0.9346 - val_loss: 2.3018 - val_accuracy: 0.5082\n",
            "Epoch 11/50\n",
            "384/459 [========================>.....] - ETA: 0s - loss: 0.1293 - accuracy: 0.9766\n",
            "Reach accuracy of 95% and stop training!\n",
            "459/459 [==============================] - 0s 901us/sample - loss: 0.1336 - accuracy: 0.9717 - val_loss: 3.1867 - val_accuracy: 0.4754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToxroTOZy3Az",
        "colab_type": "text"
      },
      "source": [
        "USE MULTIPLE LAYER LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dUDzbxmzirU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#multiple layers lstm related inputs\n",
        "lstm_layers = 3\n",
        "layers = 3\n",
        "units = 32\n",
        "lstm_n = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvjNP4Hk4WXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "0607ca36-d72b-4f3f-fed1-187f55147f32"
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(1000, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model2.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model2.fit(train_vec, training_labels,\n",
        "           validation_data=(val_vec, validation_labels),\n",
        "           epochs=30, \n",
        "           callbacks = [ checkpoint(model_name), callbacks])"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/30\n",
            "459/459 [==============================] - 7s 16ms/sample - loss: 1.6106 - accuracy: 0.1852 - val_loss: 1.6091 - val_accuracy: 0.1967\n",
            "Epoch 2/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 1.6080 - accuracy: 0.2963 - val_loss: 1.6069 - val_accuracy: 0.3115\n",
            "Epoch 3/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 1.6018 - accuracy: 0.2810 - val_loss: 1.5979 - val_accuracy: 0.2896\n",
            "Epoch 4/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 1.5669 - accuracy: 0.3704 - val_loss: 1.5563 - val_accuracy: 0.2896\n",
            "Epoch 5/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 1.4165 - accuracy: 0.3769 - val_loss: 1.4788 - val_accuracy: 0.3115\n",
            "Epoch 6/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 1.1812 - accuracy: 0.4118 - val_loss: 1.4173 - val_accuracy: 0.3224\n",
            "Epoch 7/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.9869 - accuracy: 0.5054 - val_loss: 1.4469 - val_accuracy: 0.3989\n",
            "Epoch 8/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.8391 - accuracy: 0.5839 - val_loss: 1.5385 - val_accuracy: 0.4536\n",
            "Epoch 9/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.7473 - accuracy: 0.6340 - val_loss: 1.6442 - val_accuracy: 0.4645\n",
            "Epoch 10/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.6370 - accuracy: 0.7124 - val_loss: 1.7752 - val_accuracy: 0.4372\n",
            "Epoch 11/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.5014 - accuracy: 0.7603 - val_loss: 2.3259 - val_accuracy: 0.3770\n",
            "Epoch 12/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.4091 - accuracy: 0.8170 - val_loss: 2.2015 - val_accuracy: 0.5027\n",
            "Epoch 13/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.3218 - accuracy: 0.8954 - val_loss: 2.3480 - val_accuracy: 0.4918\n",
            "Epoch 14/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.2966 - accuracy: 0.9237 - val_loss: 2.6643 - val_accuracy: 0.4536\n",
            "Epoch 15/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.2760 - accuracy: 0.9303 - val_loss: 2.8030 - val_accuracy: 0.4699\n",
            "Epoch 16/30\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.2187 - accuracy: 0.9455 - val_loss: 2.7837 - val_accuracy: 0.4645\n",
            "Epoch 17/30\n",
            "448/459 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.9554\n",
            "Reach accuracy of 95% and stop training!\n",
            "459/459 [==============================] - 1s 1ms/sample - loss: 0.1543 - accuracy: 0.9564 - val_loss: 2.8487 - val_accuracy: 0.4973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff79e579d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_aWjz0goiJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_mul(layers, units, lstm_layers, lstm_n, num_classes):\n",
        "  \"\"\"create an instance of a multi-layer LSTM. \n",
        "\n",
        "    # Arguments\n",
        "        lstm_layers: int, number of Bidirectional layers in the LSTM\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        lstm_n: int, the number of nuerons in LSTM layers\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        A multi-layer LSTM model instance.\n",
        "  \"\"\"\n",
        "  op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "  model = models.Sequential()\n",
        "  model.add(Embedding(embedding_input, embedding_output))\n",
        "\n",
        "  for i in range(lstm_layers -1):\n",
        "    if i < lstm_layers-1 :\n",
        "      model.add(Bidirectional(tf.keras.layers.LSTM(lstm_n, return_sequences = True)))\n",
        "      lstm_n = lstm_n//2\n",
        "    else:\n",
        "      model.add(Bidirectional(tf.keras.layers.LSTM(lstm_n)))\n",
        "    \n",
        "  for i in range(layers -1):\n",
        "    model.add(Dense(units, activation = 'relu'))\n",
        "    units = units//2\n",
        "  \n",
        "  model.add(Dense(units = op_units, activation = op_activation))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afq16AlDyGov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_lstm_model = lstm_mul(layers, units, lstm_layers, lstm_n, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly8VAdY0y9FE",
        "colab_type": "code",
        "outputId": "e130ae70-1b54-4b97-aa05-d30523c5efd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "m_lstm_model.summary()"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_21 (Embedding)     (None, None, 16)          16000     \n",
            "_________________________________________________________________\n",
            "bidirectional_29 (Bidirectio (None, None, 64)          12544     \n",
            "_________________________________________________________________\n",
            "bidirectional_30 (Bidirectio (None, None, 32)          10368     \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, None, 32)          1056      \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, None, 16)          528       \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, None, 5)           85        \n",
            "=================================================================\n",
            "Total params: 40,581\n",
            "Trainable params: 40,581\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IQivKPJzIeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_lstm_model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__h1ykqqy_Iz",
        "colab_type": "code",
        "outputId": "dac078e0-2001-4810-a0d6-59ff11406113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "model_name = 'm_lstm.h5'\n",
        "\n",
        "multiple_lstm_history = m_lstm_model.fit(train_vec, training_labels,\n",
        "                                  validation_data=(val_vec, validation_labels),\n",
        "                                  epochs=NUM_EPOCHS,\n",
        "                                  callbacks = [checkpoint(model_name), callbacks])"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/50\n",
            " 32/459 [=>............................] - ETA: 1:05WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  assertion failed: [] [Condition x == y did not hold element-wise:] [x (loss/dense_80_loss/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [32 1] [y (loss/dense_80_loss/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [32 24]\n\t [[node loss/dense_80_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_217028]\n\nFunction call stack:\ndistributed_function\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-194-a7a1cae87b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                   callbacks = [checkpoint(model_name), callbacks])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m                       total_epochs=1)\n\u001b[1;32m    371\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 372\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    683\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-3a80d7d4a932>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mmyCallbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mACCURACY_STOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nReach accuracy of 95% and stop training!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNXQV6bb5JYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "d533d52a-3539-4e34-b903-26c162c16922"
      },
      "source": [
        "m_lstm_model.fit(train_vec, training_labels,\n",
        "                                  validation_data=(val_vec, validation_labels),\n",
        "                                  epochs=NUM_EPOCHS)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 459 samples, validate on 183 samples\n",
            "Epoch 1/50\n",
            "\r 32/459 [=>............................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-195-cc5b5bd5d8b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m m_lstm_model.fit(train_vec, training_labels,\n\u001b[1;32m      2\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                   epochs=NUM_EPOCHS)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  assertion failed: [] [Condition x == y did not hold element-wise:] [x (loss/dense_80_loss/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [32 1] [y (loss/dense_80_loss/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [32 24]\n\t [[node loss/dense_80_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_217028]\n\nFunction call stack:\ndistributed_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgzBEyX2zb_V",
        "colab_type": "text"
      },
      "source": [
        "USE GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iENZkUS-ycNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gru related inputs \n",
        "gru_n = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX1JmPeznPTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gru_model(layers, units, gru_n, num_classes):\n",
        "  \"\"\"create an instance of GRU. \n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        gru_n: int, number of neurons in the GRU layer\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        A single layer LSTM model instance.\n",
        "  \"\"\"\n",
        "  op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "  model = models.Sequential()\n",
        "  model.add(Embedding(embedding_input, embedding_output, input_length = 24))\n",
        "  model.add(Bidirectional(tf.keras.layers.GRU(gru_n)))\n",
        "\n",
        "  for i in range(layers-1):\n",
        "    model.add(Dense(units, activation ='relu'))\n",
        "    units = units//2\n",
        "  \n",
        "  model.add(Dense(units = op_units, activation = op_activation))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzvZKZoqyUmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_model = gru_model(layers, units, gru_n, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkIpxubNxUOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49SNmHc_xSWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BspZTqB7z9jY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'gru.h5'\n",
        "\n",
        "gru_model_history = gru_model.fit(train_vec, training_labels,\n",
        "                              validation_data=(val_vec, validation_labels),\n",
        "                              epochs=NUM_EPOCHS, \n",
        "                              callbacks = [checkpoint(model_name), callbacks])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SwLGxV7rrG8",
        "colab_type": "text"
      },
      "source": [
        "MODEL PERFORMANCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b-jwoaTjOy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRHVCIxIjP84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4dqPcXIjvyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMXrnsq3vKbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clear the trained models\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}